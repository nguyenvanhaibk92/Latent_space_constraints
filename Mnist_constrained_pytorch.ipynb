{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc4e7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "SIREN compression ratio: 2.04:1\n",
      "SIREN parameter count: 385\n",
      "Model parameters: 1,190,929\n",
      "Loading MNIST data...\n",
      "Training samples: 60000\n",
      "Test samples: 10000\n",
      "Batch size: 64\n",
      "Starting SIREN autoencoder training...\n",
      "Epoch   0 | Train Loss: 0.231135 | Test Loss: 0.230758 | Time: 6.87s\n",
      "Epoch   1 | Train Loss: 0.230177 | Test Loss: 0.229776 | Time: 6.83s\n",
      "Epoch   2 | Train Loss: 0.229096 | Test Loss: 0.228525 | Time: 6.87s\n",
      "Epoch   3 | Train Loss: 0.227310 | Test Loss: 0.225712 | Time: 6.74s\n",
      "Epoch   4 | Train Loss: 0.217593 | Test Loss: 0.192100 | Time: 6.82s\n",
      "Epoch   5 | Train Loss: 0.102762 | Test Loss: 0.071137 | Time: 6.73s\n",
      "Epoch   6 | Train Loss: 0.069719 | Test Loss: 0.069235 | Time: 6.72s\n",
      "Epoch   7 | Train Loss: 0.068674 | Test Loss: 0.068400 | Time: 6.78s\n",
      "Epoch   8 | Train Loss: 0.067825 | Test Loss: 0.067602 | Time: 6.71s\n",
      "Epoch   9 | Train Loss: 0.067147 | Test Loss: 0.067131 | Time: 6.73s\n",
      "Epoch  10 | Train Loss: 0.066701 | Test Loss: 0.066715 | Time: 6.79s\n",
      "Epoch  11 | Train Loss: 0.066253 | Test Loss: 0.066265 | Time: 6.73s\n",
      "Epoch  12 | Train Loss: 0.065773 | Test Loss: 0.065799 | Time: 6.73s\n",
      "Epoch  13 | Train Loss: 0.065329 | Test Loss: 0.065392 | Time: 6.73s\n",
      "Epoch  14 | Train Loss: 0.064931 | Test Loss: 0.065001 | Time: 6.72s\n",
      "Epoch  15 | Train Loss: 0.064540 | Test Loss: 0.064608 | Time: 6.71s\n",
      "Epoch  16 | Train Loss: 0.064154 | Test Loss: 0.064198 | Time: 6.75s\n",
      "Epoch  17 | Train Loss: 0.063774 | Test Loss: 0.063813 | Time: 6.69s\n",
      "Epoch  18 | Train Loss: 0.063410 | Test Loss: 0.063445 | Time: 6.74s\n",
      "Epoch  19 | Train Loss: 0.063081 | Test Loss: 0.063086 | Time: 6.72s\n",
      "Epoch  20 | Train Loss: 0.062775 | Test Loss: 0.062773 | Time: 6.69s\n",
      "Epoch  21 | Train Loss: 0.062505 | Test Loss: 0.062491 | Time: 6.68s\n",
      "Epoch  22 | Train Loss: 0.062248 | Test Loss: 0.062216 | Time: 6.72s\n",
      "Epoch  23 | Train Loss: 0.061968 | Test Loss: 0.061902 | Time: 6.71s\n",
      "Epoch  24 | Train Loss: 0.061732 | Test Loss: 0.061681 | Time: 6.67s\n",
      "Epoch  25 | Train Loss: 0.061536 | Test Loss: 0.061466 | Time: 6.73s\n",
      "Epoch  26 | Train Loss: 0.061352 | Test Loss: 0.061288 | Time: 6.76s\n",
      "Epoch  27 | Train Loss: 0.061183 | Test Loss: 0.061108 | Time: 6.92s\n",
      "Epoch  28 | Train Loss: 0.061018 | Test Loss: 0.060951 | Time: 6.76s\n",
      "Epoch  29 | Train Loss: 0.060869 | Test Loss: 0.060802 | Time: 6.76s\n",
      "Epoch  30 | Train Loss: 0.060728 | Test Loss: 0.060634 | Time: 6.75s\n",
      "Epoch  31 | Train Loss: 0.060594 | Test Loss: 0.060489 | Time: 6.70s\n",
      "Epoch  32 | Train Loss: 0.060464 | Test Loss: 0.060364 | Time: 6.77s\n",
      "Epoch  33 | Train Loss: 0.060333 | Test Loss: 0.060233 | Time: 6.75s\n",
      "Epoch  34 | Train Loss: 0.060211 | Test Loss: 0.060128 | Time: 6.80s\n",
      "Epoch  35 | Train Loss: 0.060090 | Test Loss: 0.060002 | Time: 6.75s\n",
      "Epoch  36 | Train Loss: 0.059968 | Test Loss: 0.059868 | Time: 6.76s\n",
      "Epoch  37 | Train Loss: 0.059854 | Test Loss: 0.059747 | Time: 6.74s\n",
      "Epoch  38 | Train Loss: 0.059734 | Test Loss: 0.059629 | Time: 6.74s\n",
      "Epoch  39 | Train Loss: 0.059622 | Test Loss: 0.059505 | Time: 6.75s\n",
      "Epoch  40 | Train Loss: 0.059506 | Test Loss: 0.059394 | Time: 6.80s\n",
      "Epoch  41 | Train Loss: 0.059393 | Test Loss: 0.059280 | Time: 6.73s\n",
      "Epoch  42 | Train Loss: 0.059275 | Test Loss: 0.059180 | Time: 6.74s\n",
      "Epoch  43 | Train Loss: 0.059158 | Test Loss: 0.059058 | Time: 6.69s\n",
      "Epoch  44 | Train Loss: 0.059033 | Test Loss: 0.058904 | Time: 6.68s\n",
      "Epoch  45 | Train Loss: 0.058910 | Test Loss: 0.058774 | Time: 6.69s\n",
      "Epoch  46 | Train Loss: 0.058772 | Test Loss: 0.058655 | Time: 6.73s\n",
      "Epoch  47 | Train Loss: 0.058631 | Test Loss: 0.058475 | Time: 6.69s\n",
      "Epoch  48 | Train Loss: 0.058469 | Test Loss: 0.058310 | Time: 6.72s\n",
      "Epoch  49 | Train Loss: 0.058298 | Test Loss: 0.058126 | Time: 6.72s\n",
      "Epoch  50 | Train Loss: 0.058111 | Test Loss: 0.057901 | Time: 6.72s\n",
      "Epoch  51 | Train Loss: 0.057919 | Test Loss: 0.057723 | Time: 6.79s\n",
      "Epoch  52 | Train Loss: 0.057717 | Test Loss: 0.057505 | Time: 6.76s\n",
      "Epoch  53 | Train Loss: 0.057516 | Test Loss: 0.057296 | Time: 6.74s\n",
      "Epoch  54 | Train Loss: 0.057317 | Test Loss: 0.057129 | Time: 6.76s\n",
      "Epoch  55 | Train Loss: 0.057123 | Test Loss: 0.056935 | Time: 6.71s\n",
      "Epoch  56 | Train Loss: 0.056939 | Test Loss: 0.056739 | Time: 6.71s\n",
      "Epoch  57 | Train Loss: 0.056762 | Test Loss: 0.056542 | Time: 6.75s\n",
      "Epoch  58 | Train Loss: 0.056603 | Test Loss: 0.056384 | Time: 6.72s\n",
      "Epoch  59 | Train Loss: 0.056446 | Test Loss: 0.056259 | Time: 6.78s\n",
      "Epoch  60 | Train Loss: 0.056311 | Test Loss: 0.056085 | Time: 7.01s\n",
      "Epoch  61 | Train Loss: 0.056183 | Test Loss: 0.055980 | Time: 6.73s\n",
      "Epoch  62 | Train Loss: 0.056060 | Test Loss: 0.055857 | Time: 6.77s\n",
      "Epoch  63 | Train Loss: 0.055943 | Test Loss: 0.055754 | Time: 6.92s\n",
      "Epoch  64 | Train Loss: 0.055832 | Test Loss: 0.055670 | Time: 6.82s\n",
      "Epoch  65 | Train Loss: 0.055728 | Test Loss: 0.055540 | Time: 6.71s\n",
      "Epoch  66 | Train Loss: 0.055621 | Test Loss: 0.055435 | Time: 6.74s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "class SIRENLayer(nn.Module):\n",
    "    \"\"\"Single SIREN layer with sine activation.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features, omega_0=5.0, is_first=False):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                # First layer - uniform over [-1/n_in, 1/n_in]\n",
    "                self.linear.weight.uniform_(-1/in_features, 1/in_features)\n",
    "            else:\n",
    "                # Hidden layers - uniform over [-sqrt(6/n_in)/omega_0, sqrt(6/n_in)/omega_0]\n",
    "                bound = np.sqrt(6/in_features) / omega_0\n",
    "                self.linear.weight.uniform_(-bound, bound)\n",
    "            \n",
    "            # All biases are zeros\n",
    "            self.linear.bias.zero_()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.is_first:\n",
    "            return torch.sin(self.omega_0 * self.linear(x))\n",
    "        else:\n",
    "            return torch.sin(self.omega_0 * self.linear(x))\n",
    "\n",
    "class SIRENNetwork(nn.Module):\n",
    "    \"\"\"SIREN network implementation.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, omega_0=5.0):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        \n",
    "        # First layer\n",
    "        self.first_layer = SIRENLayer(in_features, hidden_features, omega_0, is_first=True)\n",
    "        \n",
    "        # Hidden layers\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            SIRENLayer(hidden_features, hidden_features, omega_0, is_first=False)\n",
    "            for _ in range(hidden_layers)\n",
    "        ])\n",
    "        \n",
    "        # Final layer (no sine activation)\n",
    "        self.final_layer = nn.Linear(hidden_features, out_features)\n",
    "        \n",
    "        # Initialize final layer\n",
    "        with torch.no_grad():\n",
    "            bound = np.sqrt(6/hidden_features) / omega_0\n",
    "            self.final_layer.weight.uniform_(-bound, bound)\n",
    "            self.final_layer.bias.zero_()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.first_layer(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.final_layer(x)\n",
    "        return x\n",
    "\n",
    "def get_siren_coordinates(latent_dim, device='cpu'):\n",
    "    \"\"\"Generate coordinate inputs for SIREN network.\"\"\"\n",
    "    indices = torch.arange(1, latent_dim + 1, dtype=torch.float32, device=device)\n",
    "    coordinates = 2.0 * indices / latent_dim - 1.0  # Scale to [-1, 1]\n",
    "    return coordinates.unsqueeze(1)  # Shape: (latent_dim, 1)\n",
    "\n",
    "class SIRENAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=64, hidden_dims=[512, 256, 128], \n",
    "                 siren_hidden_dims=[64], omega_0=5.0):\n",
    "        \"\"\"\n",
    "        SIREN-based autoencoder for MNIST compression.\n",
    "        \n",
    "        Args:\n",
    "            latent_dim: Dimension of the latent space (output of SIREN)\n",
    "            hidden_dims: List of hidden layer dimensions for encoder/decoder\n",
    "            siren_hidden_dims: Hidden dimensions for SIREN network\n",
    "            omega_0: Frequency parameter for SIREN activations\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.siren_hidden_dims = siren_hidden_dims\n",
    "        self.omega_0 = omega_0\n",
    "        \n",
    "        # Calculate total number of SIREN parameters\n",
    "        self.siren_param_count = self._count_siren_params()\n",
    "        \n",
    "        # Generate coordinate inputs for SIREN (will be moved to device later)\n",
    "        self.register_buffer('siren_coords', get_siren_coordinates(latent_dim))\n",
    "        \n",
    "        self.setup_networks()\n",
    "        \n",
    "    def _count_siren_params(self):\n",
    "        \"\"\"Count total number of parameters in SIREN network.\"\"\"\n",
    "        siren_layers = [1] + self.siren_hidden_dims + [1]\n",
    "        total_params = 0\n",
    "        for i in range(len(siren_layers) - 1):\n",
    "            n_in, n_out = siren_layers[i], siren_layers[i+1]\n",
    "            total_params += n_in * n_out + n_out  # weights + biases\n",
    "        return total_params\n",
    "        \n",
    "    def setup_networks(self):\n",
    "        \"\"\"Initialize encoder and decoder networks.\"\"\"\n",
    "        # Build encoder - outputs SIREN parameters\n",
    "        encoder_layers = []\n",
    "        input_dim = 28 * 28\n",
    "        \n",
    "        for hidden_dim in self.hidden_dims:\n",
    "            encoder_layers.extend([\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU()\n",
    "            ])\n",
    "            input_dim = hidden_dim\n",
    "        \n",
    "        # Final layer outputs SIREN parameters\n",
    "        encoder_layers.append(nn.Linear(input_dim, self.siren_param_count))\n",
    "        \n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        \n",
    "        # Build decoder\n",
    "        decoder_layers = []\n",
    "        input_dim = self.latent_dim\n",
    "        \n",
    "        for hidden_dim in reversed(self.hidden_dims):\n",
    "            decoder_layers.extend([\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU()\n",
    "            ])\n",
    "            input_dim = hidden_dim\n",
    "        \n",
    "        # Final layer to reconstruct input\n",
    "        decoder_layers.extend([\n",
    "            nn.Linear(input_dim, 28 * 28),\n",
    "            nn.Sigmoid()\n",
    "        ])\n",
    "        \n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "    \n",
    "    def _unflatten_siren_params_batch(self, flat_params):\n",
    "        \"\"\"Convert flat parameter vectors to SIREN network structure for entire batch.\"\"\"\n",
    "        siren_layers = [1] + self.siren_hidden_dims + [1]\n",
    "        batch_size = flat_params.shape[0]\n",
    "        params = []\n",
    "        idx = 0\n",
    "        \n",
    "        for i in range(len(siren_layers) - 1):\n",
    "            n_in, n_out = siren_layers[i], siren_layers[i+1]\n",
    "            \n",
    "            # Extract weights for entire batch\n",
    "            weight_size = n_in * n_out\n",
    "            weights = flat_params[:, idx:idx + weight_size].view(batch_size, n_in, n_out)\n",
    "            idx += weight_size\n",
    "            \n",
    "            # Extract biases for entire batch\n",
    "            biases = flat_params[:, idx:idx + n_out].view(batch_size, 1, n_out)\n",
    "            idx += n_out\n",
    "            \n",
    "            params.append((weights, biases))\n",
    "        \n",
    "        return params\n",
    "    \n",
    "    def siren_forward_batch(self, coords, siren_params_batch):\n",
    "        \"\"\"Vectorized forward pass for SIREN network across batch and coordinates.\"\"\"\n",
    "        batch_size = siren_params_batch[0][0].shape[0]  # Get batch size from weights\n",
    "        num_coords = coords.shape[0]\n",
    "        \n",
    "        # Expand coordinates to match batch size: (num_coords, 1) -> (batch_size, num_coords, 1)\n",
    "        x = coords.unsqueeze(0).expand(batch_size, -1, -1)  # Shape: (batch_size, num_coords, 1)\n",
    "        \n",
    "        # First layer with sine activation\n",
    "        weights, biases = siren_params_batch[0]  # weights: (batch_size, 1, hidden), biases: (batch_size, 1, hidden)\n",
    "        # Batch matrix multiply: (batch_size, num_coords, 1) @ (batch_size, 1, hidden) -> (batch_size, num_coords, hidden)\n",
    "        x = torch.sin(self.omega_0 * (torch.bmm(x, weights) + biases))\n",
    "        \n",
    "        # Hidden layers with sine activation\n",
    "        for i in range(1, len(siren_params_batch) - 1):\n",
    "            weights, biases = siren_params_batch[i]\n",
    "            x = torch.sin(self.omega_0 * (torch.bmm(x, weights) + biases))\n",
    "        \n",
    "        # Output layer (no sine activation)\n",
    "        weights, biases = siren_params_batch[-1]\n",
    "        output = torch.bmm(x, weights) + biases  # Shape: (batch_size, num_coords, 1)\n",
    "        \n",
    "        return output.squeeze(-1)  # Shape: (batch_size, num_coords)\n",
    "    \n",
    "    def encode_to_latent(self, images):\n",
    "        \"\"\"Encode images to latent space via SIREN network - fully vectorized.\"\"\"\n",
    "        # Get SIREN parameters from encoder\n",
    "        flat_siren_params = self.encoder(images)  # Shape: (batch_size, siren_param_count)\n",
    "        \n",
    "        # Unflatten SIREN parameters for entire batch\n",
    "        siren_params_batch = self._unflatten_siren_params_batch(flat_siren_params)\n",
    "        \n",
    "        # Generate latent codes using vectorized SIREN forward pass\n",
    "        latent_codes = self.siren_forward_batch(self.siren_coords, siren_params_batch)\n",
    "        \n",
    "        return latent_codes\n",
    "    \n",
    "    def forward(self, images):\n",
    "        \"\"\"Forward pass through the entire autoencoder.\"\"\"\n",
    "        # Encode to latent space via SIREN\n",
    "        latent_code = self.encode_to_latent(images)\n",
    "        # Decode back to image space\n",
    "        reconstructed = self.decoder(latent_code)\n",
    "        return reconstructed\n",
    "    \n",
    "    def encode_images(self, images):\n",
    "        \"\"\"Encode images to latent space.\"\"\"\n",
    "        return self.encode_to_latent(images)\n",
    "    \n",
    "    def decode_latent(self, latent_codes):\n",
    "        \"\"\"Decode latent codes to images.\"\"\"\n",
    "        return self.decoder(latent_codes)\n",
    "    \n",
    "    def get_compression_ratio(self):\n",
    "        \"\"\"Calculate compression ratio.\"\"\"\n",
    "        original_size = 28 * 28  # 784 pixels\n",
    "        compressed_size = self.siren_param_count\n",
    "        compression_ratio = original_size / compressed_size\n",
    "        return compression_ratio\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, lr=0.001, momentum=0.9, loss_type='mse'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            loss_type: 'mse' for mean squared error or 'bce' for binary cross-entropy\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.loss_type = loss_type\n",
    "        self.optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "        \n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'test_loss': []\n",
    "        }\n",
    "        \n",
    "        # Choose loss function\n",
    "        if loss_type == 'mse':\n",
    "            self.loss_fn = nn.MSELoss()\n",
    "        elif loss_type == 'bce':\n",
    "            self.loss_fn = nn.BCELoss()\n",
    "        else:\n",
    "            raise ValueError(\"loss_type must be 'mse' or 'bce'\")\n",
    "    \n",
    "    def train_step(self, batch):\n",
    "        \"\"\"Single training step.\"\"\"\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        reconstructed = self.model(batch)\n",
    "        loss = self.loss_fn(reconstructed, batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def train_epoch(self, train_loader):\n",
    "        \"\"\"Train for one epoch.\"\"\"\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_images, _ in train_loader:\n",
    "            batch_images = batch_images.to(device)\n",
    "            loss = self.train_step(batch_images)\n",
    "            total_loss += loss\n",
    "            num_batches += 1\n",
    "        \n",
    "        return total_loss / num_batches\n",
    "    \n",
    "    def evaluate(self, test_loader):\n",
    "        \"\"\"Evaluate the model.\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        total_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_images, _ in test_loader:\n",
    "                batch_images = batch_images.to(device)\n",
    "                reconstructed = self.model(batch_images)\n",
    "                loss = self.loss_fn(reconstructed, batch_images)\n",
    "                \n",
    "                total_loss += loss.item() * batch_images.size(0)\n",
    "                total_samples += batch_images.size(0)\n",
    "        \n",
    "        return total_loss / total_samples\n",
    "\n",
    "class Visualizer:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def plot_training_history(self, history, save_path=None):\n",
    "        \"\"\"Plot training history.\"\"\"\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "        \n",
    "        ax.plot(history['train_loss'], 'b-', alpha=0.8, label='Training Loss')\n",
    "        ax.plot(history['test_loss'], 'r-', alpha=0.8, label='Test Loss')\n",
    "        ax.set_title('SIREN Autoencoder Training History', fontsize=16)\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Reconstruction Loss')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_reconstructions(self, test_loader, num_examples=10, save_path=None):\n",
    "        \"\"\"Plot original vs reconstructed images.\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Get a batch of test images\n",
    "        test_images, test_labels = next(iter(test_loader))\n",
    "        test_images = test_images.to(device)\n",
    "        \n",
    "        # Select random images\n",
    "        indices = torch.randperm(test_images.size(0))[:num_examples]\n",
    "        original_images = test_images[indices]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            reconstructed = self.model(original_images)\n",
    "        \n",
    "        # Move to CPU for plotting\n",
    "        original_images = original_images.cpu()\n",
    "        reconstructed = reconstructed.cpu()\n",
    "        \n",
    "        fig, axes = plt.subplots(2, num_examples, figsize=(20, 4))\n",
    "        fig.suptitle('Original vs SIREN Reconstructed Images', fontsize=16)\n",
    "        \n",
    "        for i in range(num_examples):\n",
    "            # Original images\n",
    "            axes[0, i].imshow(original_images[i].view(28, 28), cmap='gray')\n",
    "            axes[0, i].set_title(f'Original {i+1}')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Reconstructed images\n",
    "            axes[1, i].imshow(reconstructed[i].view(28, 28), cmap='gray')\n",
    "            axes[1, i].set_title(f'SIREN Recon {i+1}')\n",
    "            axes[1, i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_siren_functions(self, test_loader, num_examples=5, save_path=None):\n",
    "        \"\"\"Visualize SIREN functions for different images.\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Get a batch of test images\n",
    "        test_images, _ = next(iter(test_loader))\n",
    "        test_images = test_images.to(device)\n",
    "        \n",
    "        # Select random images\n",
    "        indices = torch.randperm(test_images.size(0))[:num_examples]\n",
    "        selected_images = test_images[indices]\n",
    "        \n",
    "        # Get SIREN parameters for selected images\n",
    "        with torch.no_grad():\n",
    "            flat_siren_params = self.model.encoder(selected_images)\n",
    "            siren_params_batch = self.model._unflatten_siren_params_batch(flat_siren_params)\n",
    "        \n",
    "        # Create fine-grained coordinate inputs for visualization\n",
    "        coords_fine = torch.linspace(-1, 1, 200, device=device).unsqueeze(1)\n",
    "        \n",
    "        # Evaluate SIREN over fine coordinates using vectorized operation\n",
    "        with torch.no_grad():\n",
    "            siren_outputs_batch = self.model.siren_forward_batch(coords_fine, siren_params_batch)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, num_examples, figsize=(20, 4))\n",
    "        fig.suptitle('SIREN Functions for Different Images', fontsize=16)\n",
    "        \n",
    "        coords_cpu = coords_fine.cpu().numpy().flatten()\n",
    "        siren_outputs_cpu = siren_outputs_batch.cpu().numpy()\n",
    "        \n",
    "        for i in range(num_examples):\n",
    "            # Plot SIREN function\n",
    "            axes[i].plot(coords_cpu, siren_outputs_cpu[i], 'b-', linewidth=2)\n",
    "            axes[i].set_title(f'SIREN Function {i+1}')\n",
    "            axes[i].set_xlabel('Coordinate')\n",
    "            axes[i].set_ylabel('Output')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            axes[i].set_xlim(-1, 1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    def analyze_compression(self, test_loader, num_samples=100):\n",
    "        \"\"\"Analyze compression quality and statistics.\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Collect samples\n",
    "        sample_images = []\n",
    "        sample_count = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_images, _ in test_loader:\n",
    "                batch_images = batch_images.to(device)\n",
    "                sample_images.append(batch_images)\n",
    "                sample_count += batch_images.size(0)\n",
    "                if sample_count >= num_samples:\n",
    "                    break\n",
    "        \n",
    "        sample_images = torch.cat(sample_images, dim=0)[:num_samples]\n",
    "        \n",
    "        # Get reconstructions\n",
    "        with torch.no_grad():\n",
    "            reconstructed = self.model(sample_images)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse_per_image = torch.mean((sample_images - reconstructed) ** 2, dim=1)\n",
    "        mean_mse = torch.mean(mse_per_image).item()\n",
    "        std_mse = torch.std(mse_per_image).item()\n",
    "        \n",
    "        # Calculate PSNR\n",
    "        psnr_per_image = 20 * torch.log10(1.0 / torch.sqrt(mse_per_image))\n",
    "        mean_psnr = torch.mean(psnr_per_image).item()\n",
    "        \n",
    "        compression_ratio = self.model.get_compression_ratio()\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "        print(\"SIREN AUTOENCODER COMPRESSION ANALYSIS\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Latent Dimension: {self.model.latent_dim}\")\n",
    "        print(f\"SIREN Parameters: {self.model.siren_param_count}\")\n",
    "        print(f\"SIREN Hidden Dims: {self.model.siren_hidden_dims}\")\n",
    "        print(f\"Omega_0: {self.model.omega_0}\")\n",
    "        print(f\"Compression Ratio: {compression_ratio:.2f}:1\")\n",
    "        print(f\"Original Size: {28*28} pixels\")\n",
    "        print(f\"Compressed Size: {self.model.siren_param_count} SIREN params\")\n",
    "        print(f\"Mean MSE: {mean_mse:.6f} ± {std_mse:.6f}\")\n",
    "        print(f\"Mean PSNR: {mean_psnr:.2f} dB\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "def load_mnist_data(batch_size=64):\n",
    "    \"\"\"Load MNIST data using PyTorch DataLoader.\"\"\"\n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Converts to [0, 1] and changes to (C, H, W)\n",
    "        transforms.Lambda(lambda x: x.view(-1))  # Flatten to vector\n",
    "    ])\n",
    "    \n",
    "    # Load datasets\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=True, download=True, transform=transform\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=False, download=True, transform=transform\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Main training script\n",
    "if __name__ == \"__main__\":\n",
    "    # Hyperparameters\n",
    "    lr = 0.001\n",
    "    num_epochs = 500\n",
    "    batch_size = 64\n",
    "    latent_dim = 64  # Output dimension of SIREN\n",
    "    hidden_dims = [512, 256, 128]  # Encoder/decoder architecture\n",
    "    siren_hidden_dims = [128]  # SIREN network architecture\n",
    "    omega_0 = 5.0  # SIREN frequency parameter\n",
    "    loss_type = 'mse'  # 'mse' or 'bce'\n",
    "    \n",
    "    # Initialize model and trainer\n",
    "    model = SIRENAutoencoder(\n",
    "        latent_dim=latent_dim, \n",
    "        hidden_dims=hidden_dims,\n",
    "        siren_hidden_dims=siren_hidden_dims,\n",
    "        omega_0=omega_0\n",
    "    ).to(device)\n",
    "    \n",
    "    trainer = Trainer(model, lr=lr, loss_type=loss_type)\n",
    "    visualizer = Visualizer(model)\n",
    "    \n",
    "    print(f\"SIREN compression ratio: {model.get_compression_ratio():.2f}:1\")\n",
    "    print(f\"SIREN parameter count: {model.siren_param_count}\")\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Load data\n",
    "    print(\"Loading MNIST data...\")\n",
    "    train_loader, test_loader = load_mnist_data(batch_size)\n",
    "    \n",
    "    # Training loop\n",
    "    print(\"Starting SIREN autoencoder training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        tic = time.time()\n",
    "        \n",
    "        # Train\n",
    "        train_loss = trainer.train_epoch(train_loader)\n",
    "        \n",
    "        # Evaluate\n",
    "        test_loss = trainer.evaluate(test_loader)\n",
    "        \n",
    "        # Store history\n",
    "        trainer.history['train_loss'].append(train_loss)\n",
    "        trainer.history['test_loss'].append(test_loss)\n",
    "        \n",
    "        # Print progress\n",
    "        elapsed = time.time() - tic\n",
    "        print(f\"Epoch {epoch:3d} | Train Loss: {train_loss:.6f} | \"\n",
    "              f\"Test Loss: {test_loss:.6f} | Time: {elapsed:.2f}s\")\n",
    "    \n",
    "    # Final visualizations and analysis\n",
    "    print(\"\\nTraining completed! Generating visualizations...\")\n",
    "    \n",
    "    # Plot training history\n",
    "    visualizer.plot_training_history(trainer.history)\n",
    "    \n",
    "    # Plot reconstructions\n",
    "    visualizer.plot_reconstructions(test_loader, num_examples=10)\n",
    "    \n",
    "    # Plot SIREN functions\n",
    "    visualizer.plot_siren_functions(test_loader, num_examples=10)\n",
    "    \n",
    "    # Analyze compression performance\n",
    "    visualizer.analyze_compression(test_loader, num_samples=1000)\n",
    "    \n",
    "    print(\"All visualizations complete!\")\n",
    "    \n",
    "    # Additional analysis sections (similar to original)\n",
    "    \n",
    "    # Analysis for digit 4\n",
    "    print(\"\\n=== Analysis for digit 4 ===\")\n",
    "    \n",
    "    # Filter test data for digit 4\n",
    "    digit_4_data = []\n",
    "    digit_4_labels = []\n",
    "    \n",
    "    for batch_images, batch_labels in test_loader:\n",
    "        mask = batch_labels == 4\n",
    "        if mask.any():\n",
    "            digit_4_data.append(batch_images[mask])\n",
    "            digit_4_labels.append(batch_labels[mask])\n",
    "    \n",
    "    if digit_4_data:\n",
    "        digit_4_images = torch.cat(digit_4_data, dim=0)[:10]  # Take first 10\n",
    "        digit_4_dataset = TensorDataset(digit_4_images, torch.zeros(len(digit_4_images)))\n",
    "        digit_4_loader = DataLoader(digit_4_dataset, batch_size=10, shuffle=False)\n",
    "        \n",
    "        # Plot reconstructions for digit 4\n",
    "        visualizer.plot_reconstructions(digit_4_loader, num_examples=10)\n",
    "        \n",
    "        # Plot SIREN functions for digit 4\n",
    "        visualizer.plot_siren_functions(digit_4_loader, num_examples=10)\n",
    "        \n",
    "        # Plot latent representations for digit 4\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            digit_4_images = digit_4_images.to(device)\n",
    "            latent_codes = model.encode_images(digit_4_images)\n",
    "            latent_codes = latent_codes.cpu().numpy()\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for i in range(min(10, len(latent_codes))):\n",
    "            plt.plot(np.arange(latent_dim), latent_codes[i], label=f'Image {i+1}')\n",
    "        plt.title('Latent Representations of Digit 4 Images')\n",
    "        plt.xlabel('Latent Dimension index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    # SVD Analysis\n",
    "    print(\"\\n=== SVD Analysis ===\")\n",
    "    \n",
    "    # Collect all test latent representations\n",
    "    model.eval()\n",
    "    all_latent_codes = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_images, _ in test_loader:\n",
    "            batch_images = batch_images.to(device)\n",
    "            latent_codes = model.encode_images(batch_images)\n",
    "            all_latent_codes.append(latent_codes.cpu())\n",
    "    \n",
    "    all_latent_codes = torch.cat(all_latent_codes, dim=0).numpy()\n",
    "    print(f\"Latent data shape: {all_latent_codes.shape}\")\n",
    "    \n",
    "    # Perform SVD\n",
    "    U, s, Vt = np.linalg.svd(all_latent_codes, full_matrices=False)\n",
    "    \n",
    "    print(f\"U shape: {U.shape}\")\n",
    "    print(f\"Singular values shape: {s.shape}\")\n",
    "    print(f\"V transpose shape: {Vt.shape}\")\n",
    "    \n",
    "    # Analyze the singular values\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Singular values\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(s, 'o-')\n",
    "    plt.title('Singular Values')\n",
    "    plt.xlabel('Component')\n",
    "    plt.ylabel('Singular Value')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    # Plot 2: Explained variance ratio\n",
    "    variance_explained = (s**2) / np.sum(s**2)\n",
    "    cumulative_variance = np.cumsum(variance_explained)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(variance_explained, 'o-', label='Individual')\n",
    "    plt.plot(cumulative_variance, 's-', label='Cumulative')\n",
    "    plt.title('Explained Variance')\n",
    "    plt.xlabel('Component')\n",
    "    plt.ylabel('Variance Ratio')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot 3: Effective dimensionality\n",
    "    plt.subplot(1, 3, 3)\n",
    "    # Find components that explain 95% of variance\n",
    "    n_components_95 = np.where(cumulative_variance >= 0.95)[0][0] + 1\n",
    "    plt.axvline(n_components_95, color='red', linestyle='--', \n",
    "               label=f'95% variance ({n_components_95} components)')\n",
    "    plt.plot(cumulative_variance)\n",
    "    plt.title('Cumulative Variance')\n",
    "    plt.xlabel('Component')\n",
    "    plt.ylabel('Cumulative Variance')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print key statistics\n",
    "    print(f\"\\nSVD Analysis Results:\")\n",
    "    print(f\"Total components: {len(s)}\")\n",
    "    print(f\"Components for 90% variance: {np.where(cumulative_variance >= 0.90)[0][0] + 1}\")\n",
    "    print(f\"Components for 95% variance: {n_components_95}\")\n",
    "    print(f\"Components for 99% variance: {np.where(cumulative_variance >= 0.99)[0][0] + 1}\")\n",
    "    \n",
    "    # Effective dimensionality (using entropy-based measure)\n",
    "    normalized_s = s / np.sum(s)\n",
    "    effective_dim = np.exp(-np.sum(normalized_s * np.log(normalized_s + 1e-12)))\n",
    "    print(f\"Effective dimensionality: {effective_dim:.2f}\")\n",
    "    \n",
    "    # Reconstruction with different numbers of components\n",
    "    def reconstruct_with_k_components(k):\n",
    "        \"\"\"Reconstruct data using only first k components\"\"\"\n",
    "        return U[:, :k] @ np.diag(s[:k]) @ Vt[:k, :]\n",
    "    \n",
    "    k_values = [10, 50, 100, min(200, len(s))]\n",
    "    reconstruction_errors = []\n",
    "    \n",
    "    for k in k_values:\n",
    "        if k <= len(s):\n",
    "            reconstructed = reconstruct_with_k_components(k)\n",
    "            error = np.mean((all_latent_codes - reconstructed)**2)\n",
    "            reconstruction_errors.append(error)\n",
    "            print(f\"Reconstruction error with {k} components: {error:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
